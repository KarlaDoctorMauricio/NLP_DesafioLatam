{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\52477\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (0.24.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (9.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\52477\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "Installing collected packages: transformers, sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1 transformers-4.46.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\52477\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the enviroment\n",
    "DATA_PATH = r\"data\"\n",
    "CHROMA_PATH = r\"chroma_db\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "collection = chroma_client.get_or_create_collection(name = \"courses\")\n",
    "files = pd.read_csv(\"InterestingLinks.csv\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo original sobrescrito: data\\0.txt\n",
      "Archivo original sobrescrito: data\\1.txt\n",
      "Archivo original sobrescrito: data\\10.txt\n",
      "Archivo original sobrescrito: data\\11.txt\n",
      "Archivo original sobrescrito: data\\12.txt\n",
      "Archivo original sobrescrito: data\\13.txt\n",
      "Archivo original sobrescrito: data\\14.txt\n",
      "Archivo original sobrescrito: data\\15.txt\n",
      "Archivo original sobrescrito: data\\16.txt\n",
      "Archivo original sobrescrito: data\\17.txt\n",
      "Archivo original sobrescrito: data\\18.txt\n",
      "Archivo original sobrescrito: data\\19.txt\n",
      "Archivo original sobrescrito: data\\2.txt\n",
      "Archivo original sobrescrito: data\\20.txt\n",
      "Archivo original sobrescrito: data\\21.txt\n",
      "Archivo original sobrescrito: data\\22.txt\n",
      "Archivo original sobrescrito: data\\3.txt\n",
      "Archivo original sobrescrito: data\\4.txt\n",
      "Archivo original sobrescrito: data\\5.txt\n",
      "Archivo original sobrescrito: data\\6.txt\n",
      "Archivo original sobrescrito: data\\7.txt\n",
      "Archivo original sobrescrito: data\\8.txt\n",
      "Archivo original sobrescrito: data\\9.txt\n"
     ]
    }
   ],
   "source": [
    "def remove_emojis(text):\n",
    "    # Expresión regular que cubre la mayoría de los emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\\U0001F600-\\U0001F64F\"      # Emoticonos\n",
    "        \"\\U0001F300-\\U0001F5FF\"      # Símbolos y pictogramas\n",
    "        \"\\U0001F680-\\U0001F6FF\"      # Transporte y mapas\n",
    "        \"\\U0001F700-\\U0001F77F\"      # Alquimia y símbolos\n",
    "        \"\\U0001F780-\\U0001F7FF\"      # Geometría y símbolos varios\n",
    "        \"\\U0001F800-\\U0001F8FF\"      # Suplemento de flechas\n",
    "        \"\\U0001F900-\\U0001F9FF\"      # Emoticonos adicionales\n",
    "        \"\\U0001FA00-\\U0001FA6F\"      # Emojis varios\n",
    "        \"\\U0001FA70-\\U0001FAFF\"      # Más emojis\n",
    "        \"\\U00002702-\\U000027B0\"      # Caracteres varios (usados para simbolos de puntuación, etc.)\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Reemplazar los emojis encontrados por una cadena vacía\n",
    "    return re.sub(emoji_pattern, '', text)\n",
    "\n",
    "# Función para leer todos los archivos .txt y eliminar los emojis\n",
    "# Función para leer, limpiar y escribir los archivos .txt\n",
    "def clean_and_write_txt_files(directory_path, write_to_new_file=False):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            # Leer el archivo de texto\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                \n",
    "                # Eliminar los emojis del texto\n",
    "                cleaned_text = remove_emojis(text)\n",
    "                \n",
    "                if write_to_new_file:\n",
    "                    # Si se desea escribir a un nuevo archivo, crear un nombre único\n",
    "                    new_file_path = os.path.join(directory_path, f\"new_{filename}\")\n",
    "                    with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "                        new_file.write(cleaned_text)\n",
    "                    print(f\"Archivo limpio guardado como: {new_file_path}\")\n",
    "                else:\n",
    "                    # Si se desea sobrescribir el archivo original\n",
    "                    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                        file.write(cleaned_text)\n",
    "                    print(f\"Archivo original sobrescrito: {file_path}\")\n",
    "\n",
    "# Directorio donde están tus archivos .txt\n",
    "directory_path = 'data'\n",
    "\n",
    "# Llamar a la función para limpiar y reescribir los archivos\n",
    "# Si `write_to_new_file` es True, los archivos limpios se guardarán con un prefijo \"cleaned_\"\n",
    "# Si es False, se sobrescribirán los archivos originales.\n",
    "clean_and_write_txt_files(directory_path, write_to_new_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 0}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 1}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 2}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 3}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 4}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 5}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 6}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 7}\n",
      "{'title': 'Introducción al Desarrollo Web', 'file_name': '0.txt', 'chunk_index': 8}\n",
      "{'title': 'Introducción al Análisis de datos con Python', 'file_name': '1.txt', 'chunk_index': 9}\n",
      "{'title': 'Introducción al Análisis de datos con Python', 'file_name': '1.txt', 'chunk_index': 10}\n",
      "{'title': 'Introducción al Análisis de datos con Python', 'file_name': '1.txt', 'chunk_index': 11}\n",
      "{'title': 'Introducción al Análisis de datos con Python', 'file_name': '1.txt', 'chunk_index': 12}\n",
      "{'title': 'Introducción al Análisis de datos con Python', 'file_name': '1.txt', 'chunk_index': 13}\n",
      "{'title': 'Introducción al Análisis de datos con Python', 'file_name': '1.txt', 'chunk_index': 14}\n",
      "{'title': 'UX Content Design: un puente entre el negocio y las personas usuarias', 'file_name': '10.txt', 'chunk_index': 15}\n",
      "{'title': 'Ciberseguridad en la era digital: protección de datos y desafios emergentes', 'file_name': '11.txt', 'chunk_index': 16}\n",
      "{'title': 'ARTE EN EL CÓDIGO: frameworks para crear animaciones sorprendentes en frontend', 'file_name': '12.txt', 'chunk_index': 17}\n",
      "{'title': 'De OT A IT: Descubriendo nuevas fronteras en la gestión de datos industriales', 'file_name': '13.txt', 'chunk_index': 18}\n",
      "{'title': 'UX/UI En la era remota: Estrategias para un diseño efectivo', 'file_name': '14.txt', 'chunk_index': 19}\n",
      "{'title': 'Cómo la IA cambió el juego en la ciberseguridad', 'file_name': '15.txt', 'chunk_index': 20}\n",
      "{'title': 'React para principiantes: Construyendo aplicaciones web dinámicas', 'file_name': '16.txt', 'chunk_index': 21}\n",
      "Desentrañando el Machine Learning: Python como la llave del éxito\n",
      "{'title': 'UX/UI: Conceptos básicos para principiantes', 'file_name': '18.txt', 'chunk_index': 22}\n",
      "{'title': 'Abriendo caminos en STEM: Data Science con perspectiva de género', 'file_name': '19.txt', 'chunk_index': 23}\n",
      "{'title': 'Bases de GIT, GITHUB', 'file_name': '2.txt', 'chunk_index': 24}\n",
      "{'title': 'Bases de GIT, GITHUB', 'file_name': '2.txt', 'chunk_index': 25}\n",
      "{'title': 'Bases de GIT, GITHUB', 'file_name': '2.txt', 'chunk_index': 26}\n",
      "{'title': 'Bases de GIT, GITHUB', 'file_name': '2.txt', 'chunk_index': 27}\n",
      "{'title': 'Construye una App Fullstack con Next.JS, Prisma y Shadcn/cn', 'file_name': '20.txt', 'chunk_index': 28}\n",
      "{'title': 'Hacking ético en acción: Experiencias y práctica real', 'file_name': '21.txt', 'chunk_index': 29}\n",
      "Hábitos de estudio para cursos intensivos\n",
      "{'title': 'CSS Avanzado', 'file_name': '3.txt', 'chunk_index': 30}\n",
      "{'title': 'CSS Avanzado', 'file_name': '3.txt', 'chunk_index': 31}\n",
      "{'title': 'CSS Avanzado', 'file_name': '3.txt', 'chunk_index': 32}\n",
      "{'title': 'CSS Avanzado', 'file_name': '3.txt', 'chunk_index': 33}\n",
      "{'title': 'CSS Avanzado', 'file_name': '3.txt', 'chunk_index': 34}\n",
      "{'title': 'Programación con Python para el análisis de datos', 'file_name': '4.txt', 'chunk_index': 35}\n",
      "{'title': 'Programación con Python para el análisis de datos', 'file_name': '4.txt', 'chunk_index': 36}\n",
      "{'title': 'Programación con Python para el análisis de datos', 'file_name': '4.txt', 'chunk_index': 37}\n",
      "{'title': 'Programación con Python para el análisis de datos', 'file_name': '4.txt', 'chunk_index': 38}\n",
      "{'title': 'Programación con Python para el análisis de datos', 'file_name': '4.txt', 'chunk_index': 39}\n",
      "{'title': 'Aprende Power BI desde cero', 'file_name': '5.txt', 'chunk_index': 40}\n",
      "Aprende a analizar datos con Python\n",
      "{'title': 'Aprende a analizar datos con Python II', 'file_name': '7.txt', 'chunk_index': 41}\n",
      "{'title': 'Redes neuronales desde cero: Un enfoque practico y fácil de entender', 'file_name': '8.txt', 'chunk_index': 42}\n",
      "GIT Y GITHUB PARA PRINCIPIANTES: Controla tu código como un profesional\n"
     ]
    }
   ],
   "source": [
    "# Cargar los archivos de texto\n",
    "documents = []\n",
    "metadata = []\n",
    "ids = []\n",
    "j = 0\n",
    "#Loading the document\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    if filename.endswith(\".txt\"):\n",
    "            try:\n",
    "                file_path = os.path.join(DATA_PATH, filename)\n",
    "                loader = TextLoader(file_path)  # Usamos TextLoader para cargar el archivo de texto\n",
    "                raw_documents = loader.load()\n",
    "\n",
    "                # Dividir el documento en trozos (chunks)\n",
    "                text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=300,\n",
    "                    chunk_overlap=100,\n",
    "                    length_function=len,\n",
    "                    is_separator_regex=False,\n",
    "                )\n",
    "\n",
    "                chunks = text_splitter.split_documents(raw_documents)  # Preparar los chunks para ser agregados a Chroma\n",
    "\n",
    "                # Procesar cada chunk para agregarlo a Chroma\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    documents.append(chunk.page_content)\n",
    "                    embedding = model.encode([chunk.page_content])[0]\n",
    "\n",
    "                    # Asignar el título y otros metadatos al documento\n",
    "                    chunk_metadata = {\n",
    "                        \"title\": files['title'].iloc[int(filename[:-4])],  # Asignamos el título a los metadatos\n",
    "                        \"file_name\": filename,  # Puedes agregar otros metadatos si lo deseas\n",
    "                        \"chunk_index\": j  # Si necesitas un índice de chunk (opcional)\n",
    "                    }\n",
    "                    print(chunk_metadata)\n",
    "                    metadata.append(chunk_metadata)\n",
    "                    ids.append(\"ID\" + str(j))\n",
    "                    j+=1\n",
    "            except:\n",
    "                print(files['title'].iloc[int(filename[:-4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding to chromadb\n",
    "collection.upsert(\n",
    "    documents = documents,\n",
    "    metadatas = metadata,\n",
    "    ids = ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef5b8d18e6fdfd933dcf2d87676eea39b16d717784d6db55cec332fd8bca603e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
